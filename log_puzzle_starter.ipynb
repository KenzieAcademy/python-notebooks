{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Log Puzzle Starter.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FH1MR4DfuVd2"
      },
      "source": [
        "# Log Puzzle Starter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIctg3ZauRdp"
      },
      "source": [
        "\"\"\"\n",
        "Log Puzzle exercise\n",
        "\n",
        "Copyright 2010 Google Inc.\n",
        "Licensed under the Apache License, Version 2.0\n",
        "http://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Given an Apache logfile, find the puzzle URLs and download the images.\n",
        "\n",
        "Here's what a puzzle URL looks like (spread out onto multiple lines):\n",
        "10.254.254.28 - - [06/Aug/2007:00:13:48 -0700] \"GET /~foo/puzzle-bar-aaab.jpg\n",
        "HTTP/1.0\" 302 528 \"-\" \"Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US;\n",
        "rv:1.8.1.6) Gecko/20070725 Firefox/2.0.0.6\"\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import re\n",
        "import sys\n",
        "import urllib.request\n",
        "import argparse\n",
        "\n",
        "\n",
        "def read_urls(filename):\n",
        "    \"\"\"Returns a list of the puzzle URLs from the given log file,\n",
        "    extracting the hostname from the filename itself, sorting\n",
        "    alphabetically in increasing order, and screening out duplicates.\n",
        "    \"\"\"\n",
        "    # extract the server's hostname from the filename\n",
        "    host = filename[filename.index(\"_\") + 1:]\n",
        "    pattern = re.compile(r\"GET (\\S+)\")  # pre-compile our regex pattern\n",
        "    url_dict = {}\n",
        "    with open(filename) as f:\n",
        "        # search each line of the log file for a puzzle image\n",
        "        for line in f:\n",
        "            match = pattern.search(line)\n",
        "            path = match.group(1)\n",
        "            # if this line contains a puzzle image, combine its\n",
        "            # path with the server name\n",
        "            if \"puzzle\" in path:\n",
        "                # we found a puzzle piece! build the full URL!\n",
        "                # use a dictionary to de-duplicate the URLs\n",
        "                url_dict[f\"http://{host}{path}\"] = 1\n",
        "    # TODO: update the `sorted()` call to use a key= function to sort by the\n",
        "    # last letter grouping of letters within each url\n",
        "    return sorted(url_dict)\n",
        "\n",
        "\n",
        "def download_images(img_urls, dest_dir):\n",
        "    \"\"\"Given the URLs already in the correct order, downloads\n",
        "    each image into the given directory.\n",
        "    Gives the images local filenames img0, img1, and so on.\n",
        "    Creates an index.html in the directory with an <img> tag\n",
        "    to show each local image file.\n",
        "    Creates the directory if necessary.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(dest_dir):\n",
        "        os.makedirs(dest_dir)\n",
        "\n",
        "    # open an index.html file within the dest_dir for writing\n",
        "    # write the surrounding HTML tags to the HTML file\n",
        "    for i, url in enumerate(img_urls):\n",
        "        filename = f\"img{i}\"\n",
        "        print(f\"Retrieving {i+1} of {len(img_urls)}...\")\n",
        "        urllib.request.urlretrieve(url, os.path.join(dest_dir, filename))\n",
        "        # write the img tag for this image to the HTML file\n",
        "    # write the closing surrounding HTML tags to the HTML file\n",
        "\n",
        "\n",
        "def create_parser():\n",
        "    \"\"\"Creates an argument parser object.\"\"\"\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('-d', '--todir',\n",
        "                        help='destination directory for downloaded images')\n",
        "    parser.add_argument('logfile', help='apache logfile to extract urls from')\n",
        "\n",
        "    return parser\n",
        "\n",
        "\n",
        "def main(args):\n",
        "    \"\"\"Parses args, scans for URLs, gets images from URLs.\"\"\"\n",
        "    parser = create_parser()\n",
        "\n",
        "    if not args:\n",
        "        parser.print_usage()\n",
        "        sys.exit(1)\n",
        "\n",
        "    parsed_args = parser.parse_args(args)\n",
        "\n",
        "    img_urls = read_urls(parsed_args.logfile)\n",
        "\n",
        "    if parsed_args.todir:\n",
        "        download_images(img_urls, parsed_args.todir)\n",
        "    else:\n",
        "        print('\\n'.join(img_urls))\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main(sys.argv[1:])\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}